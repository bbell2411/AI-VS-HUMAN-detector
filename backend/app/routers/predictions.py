from fastapi import APIRouter, HTTPException, status, Depends
from app.models.prediction import PredictionRecord
from app.schemas.prediction import PredictionRequest, PredictionResponse,ContentType, ModelInfoResponse, ModelInfo
from sqlalchemy.orm import Session
from app.database import get_db
from app.services.ml_service import MLService

ml_service = MLService()

router = APIRouter(tags=["Predictions"])

@router.post(
    "/predictions/",
    response_model=PredictionResponse,
    status_code=status.HTTP_200_OK,
    summary="Predict text origin",
    description="Submit text for analysis to determine if it was generated by AI or written by a human."
    )
async def predict_text_origin(
    request: PredictionRequest,
    db:Session=Depends(get_db)
    ) ->PredictionResponse:

    if len(request.text.strip()) < 10:
        raise HTTPException(status_code=400, detail="Text must be at least 10 characters long")
    if len(request.text) >10000:
       raise HTTPException(status_code=422, detail="Text is too long")
   
    try:
        result= await ml_service.predict_text_origin(request)
        db_record = PredictionRecord(
            text_content=request.text,
            content_type=request.content_type.value,  
            prediction_result=result.result,
            confidence_score=result.confidence,
            processing_time_ms=result.processing_time_ms,
            text_length=result.text_length
        )
        db.add(db_record)
        db.commit()
        db.refresh(db_record) 
        return result
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code= status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"prediction failed: {str(e)}"
            )
@router.get(
    "/predictions/models/info",
    response_model=ModelInfoResponse,
    summary="Gets model information",
    description="Get information about the ML models currently loaded."
)
async def get_model_info() -> ModelInfoResponse:
    """Gets information about loaded model and their capabilities"""
    if ml_service.model == None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Model not loaded, service currently unavailable"
                )
    try:
        model_info = ModelInfo(
        name="SVM + PCA AI Text Detector",
        version="1.0.0",
        status="loaded" if ml_service.model is not None else "not_loaded",
        accuracy="60%",
        features=["TF-IDF", "linguistic_features", "content_type", "PCA"]
    )
        return ModelInfoResponse(
        models={"text_classifier":model_info},
        supported_content_types=[c.value for c in ContentType],
        max_text_length=10000,
        min_text_length=1
    )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get model info: {str(e)}"
        )
@router.get(
    "/predictions/",
    response_model=list[PredictionResponse],
    summary="Get all predictions",
    description="Retrieve all prediction records from the database."
) 
async def get_predictions(db:Session=Depends(get_db)):
    """Retrieve all predictions"""
    try:
        db_predictions=db.query(PredictionRecord).all()
        if not db_predictions:
            return [] 
        predictions=[]
        for pred in db_predictions:
            response=PredictionResponse(
                result= pred.prediction_result,
                confidence= pred.confidence_score,
                processing_time_ms=pred.processing_time_ms,
                timestamp=pred.created_at,
                text_length=pred.text_length
            )    
            predictions.append(response)
        return predictions
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to retrieve predictions: {str(e)}"
        )
        
    
@router.get(
    "/predictions/{id}",
    response_model=PredictionResponse,
    summary="get prediction by id",
    description="Retrieve a specific prediction record by its ID."
)
async def get_prediction_by_id(id:int, db:Session=Depends(get_db)):
    """Get prediction by it's specific ID"""
    try:
        if id <= 0:
            raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Prediction ID must be a positive integer"
        )
        
        db_pred=db.query(PredictionRecord).filter(
            PredictionRecord.id==id
        ).first()
        
        if not db_pred:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Prediction with id {id} not found."
            )
        response=PredictionResponse(
            result=db_pred.prediction_result,
            confidence=db_pred.confidence_score,
            processing_time_ms=db_pred.processing_time_ms,
            timestamp=db_pred.created_at,
            text_length=db_pred.text_length
        )
        return response
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to retrieve prediction: {str(e)}"
        )

@router.delete(
    "/predictions/{pred_id}",
    status_code=status.HTTP_204_NO_CONTENT,
    summary="Delete prediction by ID",
    description="Delete a specific prediction record by its ID."
)
async def delete_prediction_by_id(pred_id: int, db: Session = Depends(get_db)):
    """Delete a prediction by its specific ID."""
    try:
        db_pred = db.query(PredictionRecord).filter(
            PredictionRecord.id == pred_id
        ).first()
        
        if not db_pred:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Prediction with id {pred_id} not found."
            )
            
        db.delete(db_pred)
        db.commit()
        
        return None
    
    except HTTPException:
        raise
    except Exception as e:
        db.rollback() 
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to delete prediction: {str(e)}"
        )
#2
#Docker Containerization 
# FROM python:3.13-slim

       
       