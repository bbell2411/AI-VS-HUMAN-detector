{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e6e49",
   "metadata": {},
   "source": [
    "# NUMERIC-ONLY FEATURE\n",
    "\n",
    "Quick experiment to test if the numeric-only features available can distinguish AI vs Human writing\n",
    "\n",
    "**Result**: ~55% accuracy with numeric-only feature approach vs 60.2% with full features\n",
    "\n",
    "**Conclusion**: The full features approach provides meaningful improvement over numeric-only feature approach\n",
    "\n",
    "*Note: This was an exploratory experiment. See main.py for the complete, production-ready pipeline.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2b2f2-abb6-4fc3-b72b-57e05d112291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd92279-7f60-4fed-bf22-e45949fcbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/ai_human_content_detection_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a4f578-e102-40cb-9541-6617e779ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for storing and evaluating \n",
    "results={}\n",
    "\n",
    "highest_score={\n",
    "       'model': None,\n",
    "       'score': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a03f912-6fe2-421e-b835-b772d903a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=100000),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31d3298-6562-496f-8e99-c5700b3a2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only numeric values from original data\n",
    "X_numeric=df[['word_count', 'character_count',\n",
    "       'sentence_count', 'lexical_diversity', 'avg_sentence_length',\n",
    "       'avg_word_length', 'punctuation_ratio', 'flesch_reading_ease',\n",
    "       'gunning_fog_index', 'grammar_errors', 'passive_voice_ratio',\n",
    "       'predictability_score', 'burstiness', 'sentiment_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb8a003-090d-4630-b2a5-4055d0f31336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired output\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a615a6e5-24a6-4f70-917a-79c76f9dede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "       X_numeric,\n",
    "       y,\n",
    "       test_size=0.2,\n",
    "       random_state=42,\n",
    "       stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "633fc09a-ceda-4977-9f2b-1a7fa4d64e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b000ba8-161f-4e1a-8f1a-b9f344b779ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW MODEL EVAL: RandomForest: 0.504\n",
      "RAW MODEL EVAL: LogisticRegression: 0.522\n",
      "RAW MODEL EVAL: SVM: 0.493\n",
      "RAW MODEL EVAL: KNN: 0.529\n",
      "\n",
      "Best RAW Model: KNN with accuracy: 0.529\n"
     ]
    }
   ],
   "source": [
    "# Train and eval raw model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_imputed, y_train)\n",
    "    y_pred = model.predict(X_test_imputed)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"RAW MODEL EVAL: {name}: {accuracy:.3f}\")\n",
    "best_model = max(results, key=results.get)\n",
    "if results[best_model] > highest_score[\"score\"]:\n",
    "       highest_score[\"score\"] = results[best_model]\n",
    "       highest_score[\"model\"] = best_model\n",
    "print(\"\")\n",
    "print(f\"Best RAW Model: {best_model} with accuracy: {results[best_model]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ebbc268-1667-4c1c-9e87-250fbf4d8b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "scaler = StandardScaler(with_mean=False)  \n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed) \n",
    "X_test_scaled= scaler.transform(X_test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cb9bbba-73fd-44f9-a42e-17ce4f530175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALED MODEL EVAL (DENSE): RandomForest: 0.504\n",
      "SCALED MODEL EVAL (DENSE): LogisticRegression: 0.533\n",
      "SCALED MODEL EVAL (DENSE): SVM: 0.500\n",
      "SCALED MODEL EVAL (DENSE): KNN: 0.551\n",
      "Best SCALED Model: KNN with accuracy: 0.551\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models with scaled data\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"SCALED MODEL EVAL (DENSE): {name}: {accuracy:.3f}\")\n",
    "best_model = max(results, key=results.get)\n",
    "if results[best_model] > highest_score[\"score\"]:\n",
    "       highest_score[\"score\"] = results[best_model]\n",
    "       highest_score[\"model\"] = best_model\n",
    "print(f\"Best SCALED Model: {best_model} with accuracy: {results[best_model]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d38c1f27-da64-44a6-af16-d944435b3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to capture 95% variance\n",
    "pca=PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b8a153a-6e30-4283-85e7-44dae4693cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA APPLIED MODEL EVAL RandomForest: 0.555\n",
      "PCA APPLIED MODEL EVAL LogisticRegression: 0.500\n",
      "PCA APPLIED MODEL EVAL SVM: 0.507\n",
      "PCA APPLIED MODEL EVAL KNN: 0.536\n",
      "Best PCA Model: RandomForest with accuracy: 0.555\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models with scaled + PCA data\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"PCA APPLIED MODEL EVAL {name}: {accuracy:.3f}\")\n",
    "if results[best_model] > highest_score[\"score\"]:\n",
    "       highest_score[\"score\"] = results[best_model]\n",
    "       highest_score[\"model\"] = best_model\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"Best PCA Model: {best_model} with accuracy: {results[best_model]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa1b886b-e447-48d2-bd60-005b5942ae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORING MODEL: KNN with accuracy: 0.551\n"
     ]
    }
   ],
   "source": [
    "print(f\"BEST SCORING MODEL: {highest_score['model']} with accuracy: {highest_score['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbfe101-7edf-43f9-98af-3c463c8e48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performed worse without text content "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
